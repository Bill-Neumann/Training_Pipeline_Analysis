{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Julia', 1), ('loves', 2), ('me', 2), ('a', 1), ('lot', 1), ('more', 1), ('than', 1), ('Mary', 1)])\n",
      "dict_items([('Julia', 1), ('likes', 1), ('me', 2), ('more', 1), ('than', 1), ('Mary', 1), ('loves', 1)])\n",
      "dict_items([('Julian', 1), ('likes', 1), ('basketball', 1), ('more', 1), ('than', 1), ('baseball', 1)])\n"
     ]
    }
   ],
   "source": [
    "traindoc = ['Julia loves me a lot more than Mary loves me',\n",
    "'Julia likes me more than Mary loves me',\n",
    "'Julian likes basketball more than baseball']\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for doc in traindoc:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    print (tf.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scikit-learn documentation:\n",
    "Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols \n",
    "cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size \n",
    "rather than the raw text documents with variable length.\n",
    "We will use CountVectorizer to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import vectorizers to turn text into numeric\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(traindoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball',\n",
       " 'basketball',\n",
       " 'julia',\n",
       " 'julian',\n",
       " 'likes',\n",
       " 'lot',\n",
       " 'loves',\n",
       " 'mary',\n",
       " 'me',\n",
       " 'more',\n",
       " 'than']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform training data into a 'document-term' matrix \n",
    "train1 = vect.transform(traindoc)\n",
    "train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scikit-learn documentation:\n",
    "\n",
    "In this scheme, features and samples are defined as follows:\n",
    "Each individual token occurrence frequency (normalized or not) is treated as a feature.\n",
    "The vector of all the token frequencies for a given document is considered a multivariate sample.\n",
    "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) \n",
    "occurring in the corpus.\n",
    "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. \n",
    "This specific strategy (tokenization, counting and normalization) is called the Bag of Words or \"Bag of n-grams\" representation.\n",
    "Documents are described by word occurrences while completely ignoring the relative position information of the words \n",
    "in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 2, 1, 2, 1, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this converts a sparse matrix to a dense matrix\n",
    "train1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseball</th>\n",
       "      <th>basketball</th>\n",
       "      <th>julia</th>\n",
       "      <th>julian</th>\n",
       "      <th>likes</th>\n",
       "      <th>lot</th>\n",
       "      <th>loves</th>\n",
       "      <th>mary</th>\n",
       "      <th>me</th>\n",
       "      <th>more</th>\n",
       "      <th>than</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseball  basketball  julia  julian  likes  lot  loves  mary  me  more  \\\n",
       "0         0           0      1       0      0    1      2     1   2     1   \n",
       "1         0           0      1       0      1    0      1     1   2     1   \n",
       "2         1           1      0       1      1    0      0     0   0     1   \n",
       "\n",
       "   than  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine the vocabulary and the document-term matrix together\n",
    "import pandas as pd\n",
    "pd.DataFrame(train1.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t2\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t2\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t2\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 10)\t1\n"
     ]
    }
   ],
   "source": [
    "# print the sparse matrix\n",
    "print(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now instead of count vectorizer we can use Tfidf vectorizer which normalizes data for different document sizes\n",
    "vect2 = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2.fit(traindoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2.fit(traindoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball',\n",
       " 'basketball',\n",
       " 'julia',\n",
       " 'julian',\n",
       " 'likes',\n",
       " 'lot',\n",
       " 'loves',\n",
       " 'mary',\n",
       " 'me',\n",
       " 'more',\n",
       " 'than']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = vect2.transform(traindoc)\n",
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.27804511,  0.        ,  0.        ,\n",
       "         0.36559591,  0.55609022,  0.27804511,  0.55609022,  0.21592683,\n",
       "         0.21592683],\n",
       "       [ 0.        ,  0.        ,  0.32957953,  0.        ,  0.32957953,\n",
       "         0.        ,  0.32957953,  0.32957953,  0.65915906,  0.25594791,\n",
       "         0.25594791],\n",
       "       [ 0.48359121,  0.48359121,  0.        ,  0.48359121,  0.36778358,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.28561676,\n",
       "         0.28561676]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdat=['Manju likes basketball too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = vect.transform(testdat)\n",
    "test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 11)\n",
      "[1 1 0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=2)\n",
    "k_means.fit(train1)\n",
    "print(train1.shape)\n",
    "print(k_means.labels_)\n",
    "predictor=k_means.predict(test1)\n",
    "print (predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 11)\n",
      "[1 1 0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "k_means = KMeans(n_clusters=2)\n",
    "k_means.fit(simple_train2)\n",
    "print(train2.shape)\n",
    "print(k_means.labels_)\n",
    "predictor=k_means.predict(test1)\n",
    "print (predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
